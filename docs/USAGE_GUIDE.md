# ë¬¼ë¥˜ ìˆ˜ìš”ì˜ˆì¸¡ ì‹œìŠ¤í…œ - ì‹¤í–‰ ê°€ì´ë“œ

## ë¹ ë¥¸ ì‹œì‘ (Quick Start)

### 1. í™˜ê²½ ì„¤ì •

#### Python ë²„ì „ í™•ì¸
```bash
python --version
# Python 3.8 ì´ìƒ í•„ìš”
```

#### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

ë˜ëŠ” requirements.txt ì‚¬ìš©:
```bash
pip install -r requirements.txt
```

#### requirements.txt ë‚´ìš©
```
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
```

### 2. ë°ì´í„° ì¤€ë¹„

#### í•„ìˆ˜ ì»¬ëŸ¼
```
date         : ë‚ ì§œ (ì˜ˆ: 2024.01.01)
sku_code     : SKU ì½”ë“œ
degr         : ì˜¨ë„ëŒ€ (ì˜ˆ: ëƒ‰ì¥, ëƒ‰ë™, ìƒì˜¨)
box_qty      : ë°•ìŠ¤ ìˆ˜ëŸ‰
```

#### ë°ì´í„° íŒŒì¼ ìœ„ì¹˜
```
ML/
â”œâ”€â”€ main.py
â”œâ”€â”€ demand_forecast_system.py
â””â”€â”€ shipment.csv  â† ì—¬ê¸°ì— ë°ì´í„° íŒŒì¼ ë°°ì¹˜
```

### 3. ì‹¤í–‰

#### ê¸°ë³¸ ì‹¤í–‰
```bash
cd ML
python main.py
```

#### ì‹¤í–‰ í™”ë©´
```
======================================================================
ğŸš€ ì…ê³  ë°ì´í„° ìˆ˜ìš”ì˜ˆì¸¡ ì‹œìŠ¤í…œ
======================================================================

âœ“ ë°ì´í„° íŒŒì¼ ë°œê²¬: shipment.csv

======================================================================
Step 1: ì‹œìŠ¤í…œ ì´ˆê¸°í™”
======================================================================
âœ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: outputs

======================================================================
Step 2: ë°ì´í„° ë¡œë”©
======================================================================
âœ“ ë°ì´í„° ë¡œë”© ì™„ë£Œ: 245673 rows

...
```

---

## ë‹¨ê³„ë³„ ì‹¤í–‰ ê°€ì´ë“œ

### Step 1: ì‹œìŠ¤í…œ ì´ˆê¸°í™”
```python
from demand_forecast_system import DemandForecastSystem

dfs = DemandForecastSystem(output_dir='outputs')
```

**ì„¤ëª…**:
- `output_dir`: ê²°ê³¼ íŒŒì¼ì´ ì €ì¥ë  í´ë” (ê¸°ë³¸ê°’: 'outputs')
- í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±

### Step 2: ë°ì´í„° ë¡œë”©
```python
# ë°©ë²• 1: CSV íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë”©
dfs.load_data(data_path='shipment.csv')

# ë°©ë²• 2: DataFrame ì „ë‹¬
import pandas as pd
df = pd.read_csv('shipment.csv')
dfs.load_data(df=df)

# ë°©ë²• 3: Excel íŒŒì¼
dfs.load_data(data_path='shipment.xlsx')
```

**ì§€ì› íŒŒì¼ í˜•ì‹**:
- CSV (`.csv`)
- Excel (`.xlsx`)
- TSV (`.txt`)

### Step 3: ë°ì´í„° ì „ì²˜ë¦¬
```python
dfs.preprocess_data()
```

**ìë™ ì²˜ë¦¬ ë‚´ìš©**:
- ë‚ ì§œ í˜•ì‹ ë³€í™˜
- ìš”ì¼, ì›”, ê³„ì ˆ íŠ¹ì„± ìƒì„±
- ì£¼ë§/í‰ì¼ êµ¬ë¶„
- ì˜¨ë„ëŒ€ í‘œì¤€í™”
- ê²°ì¸¡ì¹˜ ì²˜ë¦¬

**ì¶œë ¥ ì˜ˆì‹œ**:
```
âœ“ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ
  - ê¸°ê°„: 2024-01-01 ~ 2024-12-31
  - SKU ì¢…ë¥˜: 156ê°œ
  - ì˜¨ë„ëŒ€: ['ëƒ‰ì¥' 'ëƒ‰ë™' 'ìƒì˜¨']
```

### Step 4: ì§‘ê³„ ë°ì´í„° ìƒì„±
```python
dfs.create_aggregations()
```

**ìƒì„±ë˜ëŠ” ì§‘ê³„**:
- ì¼ë³„ ì§‘ê³„: SKU + ì˜¨ë„ëŒ€ë³„
- ì£¼ë³„ ì§‘ê³„: ì£¼ê°„ ë‹¨ìœ„

**ì¶œë ¥ ì˜ˆì‹œ**:
```
âœ“ ì§‘ê³„ ë°ì´í„° ìƒì„± ì™„ë£Œ
  - ì¼ë³„ ë°ì´í„°: 12,450 rows
  - ì£¼ë³„ ë°ì´í„°: 1,820 rows
```

### Step 5: íŒ¨í„´ ë¶„ì„
```python
dfs.analyze_patterns()
```

**ë¶„ì„ í•­ëª©**:
1. ìš”ì¼ë³„ ì…ê³  íŒ¨í„´
2. ì˜¨ë„ëŒ€ë³„ ì…ê³  íŒ¨í„´
3. SKUë³„ ì…ê³  íŒ¨í„´ (Top 10)
4. ê³„ì ˆë³„ ì…ê³  íŒ¨í„´

**ìƒì„± íŒŒì¼**:
- `weekday_pattern.png`
- `temperature_pattern.png`
- `sku_pattern.png`
- `seasonal_pattern.png`

### Step 6: SKU í´ëŸ¬ìŠ¤í„°ë§
```python
# 6-1. íŠ¹ì„± ì¶”ì¶œ
dfs.extract_sku_features()

# 6-2. í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
dfs.perform_sku_clustering(n_clusters=4, method='kmeans')

# 6-3. ì‹œê°í™”
dfs.visualize_clusters()
```

**íŒŒë¼ë¯¸í„°**:
- `n_clusters`: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (ê¸°ë³¸ê°’: 4)
- `method`: 'kmeans' ë˜ëŠ” 'dbscan'

**ìƒì„± íŒŒì¼**:
- `sku_clustering.png`
- `cluster_heatmap.png`

### Step 7: ìˆ˜ìš”ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
```python
dfs.build_forecast_models()
```

**êµ¬ì¶•ë˜ëŠ” ëª¨ë¸**:
1. ì´ë™í‰ê·  (Moving Average)
2. ì§€ìˆ˜í‰í™œ (Exponential Smoothing)
3. ìš”ì¼ íŒ¨í„´ ê¸°ë°˜

### Step 8: ëª¨ë¸ í‰ê°€
```python
results = dfs.evaluate_forecasts()
```

**í‰ê°€ ì§€í‘œ**:
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)

**ì¶œë ¥ ì˜ˆì‹œ**:
```
ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:
              Model     MAE    RMSE  MAPE(%)
    moving_average   45.23   67.89    18.34
exponential_smoothing   42.56   65.12    17.21
     weekday_pattern   38.90   61.45    15.67
```

### Step 9: ë¯¸ë˜ ìˆ˜ìš” ì˜ˆì¸¡
```python
forecast = dfs.generate_forecast_report(forecast_days=7)
```

**íŒŒë¼ë¯¸í„°**:
- `forecast_days`: ì˜ˆì¸¡í•  ì¼ìˆ˜ (ê¸°ë³¸ê°’: 7)

**ìƒì„± íŒŒì¼**:
- `forecast_report.csv`

### Step 10: ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
```python
# ìë™ìœ¼ë¡œ ê°€ì¥ ë§ì€ ìˆ˜ìš”ì˜ SKU ì„ íƒ
dfs.visualize_forecast()

# íŠ¹ì • SKU ì§€ì •
dfs.visualize_forecast(sku_code='2014728', days_back=30)
```

**íŒŒë¼ë¯¸í„°**:
- `sku_code`: ì‹œê°í™”í•  SKU (Noneì´ë©´ ìë™ ì„ íƒ)
- `days_back`: í‘œì‹œí•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30)

### Step 11: ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
```python
dfs.generate_summary_report()
```

**ìƒì„± íŒŒì¼**:
- `summary_report.txt`

**í¬í•¨ ë‚´ìš©**:
1. ë°ì´í„° ê¸°ë³¸ ì •ë³´
2. ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„
3. ì˜¨ë„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
4. Top 5 SKU
5. ìˆ˜ìš”ì˜ˆì¸¡ ê¸°ë°˜ ì¶”ì²œì‚¬í•­

---

## ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ì»¤ìŠ¤í…€ í´ëŸ¬ìŠ¤í„°ë§

#### ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ì‹¤í—˜
```python
for k in [2, 3, 4, 5, 6]:
    print(f"\n{'='*70}")
    print(f"Testing with {k} clusters")
    print(f"{'='*70}")

    dfs.perform_sku_clustering(n_clusters=k, method='kmeans')
    dfs.visualize_clusters()
```

#### DBSCAN ì‚¬ìš©
```python
# DBSCANì€ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ê²°ì •
dfs.perform_sku_clustering(method='dbscan')
```

### 2. íŠ¹ì • SKU ê·¸ë£¹ ë¶„ì„

```python
# íŠ¹ì • ì˜¨ë„ëŒ€ë§Œ ë¶„ì„
dfs.df_processed = dfs.df_processed[dfs.df_processed['temp_category'] == 'ëƒ‰ì¥']
dfs.create_aggregations()
dfs.analyze_patterns()
```

### 3. ë°°ì¹˜ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ íŒŒì¼ ìë™ ì²˜ë¦¬
for file in glob.glob('data/*.csv'):
    print(f"\nProcessing {file}...")

    dfs = DemandForecastSystem(output_dir=f'outputs/{file.stem}')
    dfs.load_data(data_path=file)
    dfs.preprocess_data()
    dfs.create_aggregations()
    dfs.analyze_patterns()
    dfs.extract_sku_features()
    dfs.perform_sku_clustering()
    dfs.visualize_clusters()
    dfs.build_forecast_models()
    dfs.evaluate_forecasts()
    dfs.generate_summary_report()
```

### 4. ê²°ê³¼ ë°ì´í„° í™œìš©

#### í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¶”ì¶œ
```python
# í´ëŸ¬ìŠ¤í„°ë³„ SKU ë¦¬ìŠ¤íŠ¸
for cluster_id in range(4):
    skus = dfs.sku_features[dfs.sku_features['cluster'] == cluster_id]['sku_code'].tolist()
    print(f"Cluster {cluster_id}: {skus}")

# CSVë¡œ ì €ì¥
dfs.sku_features.to_csv('outputs/sku_clusters.csv', index=False)
```

#### ì˜ˆì¸¡ ê²°ê³¼ í™œìš©
```python
# ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ
forecast_df = pd.read_csv('outputs/forecast_report.csv')

# íŠ¹ì • ë‚ ì§œì˜ ì´ ì˜ˆì¸¡ëŸ‰
date_forecast = forecast_df[forecast_df['date'] == '2024-01-15']
total_boxes = date_forecast['forecast_boxes'].sum()
print(f"2024-01-15 ì˜ˆìƒ ì…ê³ ëŸ‰: {total_boxes:.0f} boxes")

# SKUë³„ ì£¼ê°„ ì˜ˆì¸¡
weekly_forecast = forecast_df.groupby('sku_code')['forecast_boxes'].sum()
print(weekly_forecast)
```

---

## ì¶œë ¥ íŒŒì¼ ê°€ì´ë“œ

### í´ë” êµ¬ì¡°
```
outputs/
â”œâ”€â”€ weekday_pattern.png
â”œâ”€â”€ temperature_pattern.png
â”œâ”€â”€ sku_pattern.png
â”œâ”€â”€ seasonal_pattern.png
â”œâ”€â”€ sku_clustering.png
â”œâ”€â”€ cluster_heatmap.png
â”œâ”€â”€ model_comparison.png
â”œâ”€â”€ forecast_visualization.png
â”œâ”€â”€ forecast_report.csv
â””â”€â”€ summary_report.txt
```

### íŒŒì¼ë³„ ì„¤ëª…

#### 1. weekday_pattern.png
**ë‚´ìš©**: ìš”ì¼ë³„ í‰ê·  ì…ê³ ëŸ‰ ë° í‰ì¼ vs ì£¼ë§ ë¹„êµ
**í™œìš©**: ìš”ì¼ë³„ ì¸ë ¥ ë°°ì¹˜ ê³„íš

#### 2. temperature_pattern.png
**ë‚´ìš©**: ì˜¨ë„ëŒ€ë³„ ì´ ì…ê³ ëŸ‰ ë° í‰ê·  ì…ê³ ëŸ‰
**í™œìš©**: ì˜¨ë„ëŒ€ë³„ ë³´ê´€ ê³µê°„ ë°°ë¶„

#### 3. sku_pattern.png
**ë‚´ìš©**: ì…ê³ ëŸ‰ ê¸°ì¤€ Top 10 SKU
**í™œìš©**: í•µì‹¬ SKU ì‹ë³„ ë° ìš°ì„  ê´€ë¦¬

#### 4. seasonal_pattern.png
**ë‚´ìš©**: ê³„ì ˆë³„ í‰ê·  ì…ê³ ëŸ‰
**í™œìš©**: ê³„ì ˆë³„ ìš´ì˜ ì „ëµ ìˆ˜ë¦½

#### 5. sku_clustering.png
**ë‚´ìš©**:
- PCA í´ëŸ¬ìŠ¤í„° ì‹œê°í™”
- ìˆ˜ìš” vs ë³€ë™ê³„ìˆ˜ ì‚°ì ë„
- í´ëŸ¬ìŠ¤í„°ë³„ ìˆ˜ìš” ë¶„í¬
- í´ëŸ¬ìŠ¤í„°ë³„ SKU ê°œìˆ˜

**í™œìš©**: í´ëŸ¬ìŠ¤í„° íŠ¹ì„± íŒŒì•… ë° ë¶„ë¥˜ ê²€ì¦

#### 6. cluster_heatmap.png
**ë‚´ìš©**: í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± í”„ë¡œíŒŒì¼ íˆíŠ¸ë§µ
**í™œìš©**: í´ëŸ¬ìŠ¤í„° ê°„ ì°¨ì´ì  ë¹„êµ

#### 7. model_comparison.png
**ë‚´ìš©**: ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (MAE, RMSE, MAPE)
**í™œìš©**: ìµœì  ëª¨ë¸ ì„ íƒ

#### 8. forecast_visualization.png
**ë‚´ìš©**: ì„ íƒëœ SKUì˜ ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’
**í™œìš©**: ì˜ˆì¸¡ ì •í™•ë„ ì‹œê°ì  í™•ì¸

#### 9. forecast_report.csv
**êµ¬ì¡°**:
```csv
date,weekday,sku_code,temp_category,forecast_boxes
2024-01-15,ì›”,2014728,ëƒ‰ì¥,450.2
2024-01-15,ì›”,2014968,ëƒ‰ì¥,230.5
...
```
**í™œìš©**: ì¼ë³„ ì˜ˆì¸¡ ë°ì´í„° ê¸°ë°˜ ìš´ì˜ ê³„íš

#### 10. summary_report.txt
**êµ¬ì¡°**:
```
1. ë°ì´í„° ê¸°ë³¸ ì •ë³´
2. ìš”ì¼ë³„ íŒ¨í„´ ë¶„ì„
3. ì˜¨ë„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
4. Top 5 SKU
5. ìˆ˜ìš”ì˜ˆì¸¡ ê¸°ë°˜ ì¶”ì²œì‚¬í•­
```
**í™œìš©**: ê²½ì˜ì§„ ë³´ê³ ìš© ìš”ì•½ ë¦¬í¬íŠ¸

---

## ë¬¸ì œ í•´ê²° (Troubleshooting)

### 1. ë°ì´í„° ë¡œë”© ì˜¤ë¥˜

#### ì˜¤ë¥˜: "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
```python
# í•´ê²°: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
import os
file_path = os.path.abspath('shipment.csv')
dfs.load_data(data_path=file_path)
```

#### ì˜¤ë¥˜: "í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤"
```python
# í•´ê²°: ì»¬ëŸ¼ëª… í™•ì¸ ë° ë³€ê²½
df = pd.read_csv('shipment.csv')
print(df.columns)

# ì»¬ëŸ¼ëª… ë³€ê²½
df.rename(columns={'date_col': 'date', 'sku': 'sku_code'}, inplace=True)
dfs.load_data(df=df)
```

### 2. ë©”ëª¨ë¦¬ ì˜¤ë¥˜

#### ì˜¤ë¥˜: "MemoryError"
```python
# í•´ê²°: ë°ì´í„° ìƒ˜í”Œë§
df = pd.read_csv('shipment.csv')

# ìµœê·¼ 6ê°œì›”ë§Œ ì‚¬ìš©
df['date'] = pd.to_datetime(df['date'])
df = df[df['date'] >= '2024-07-01']

dfs.load_data(df=df)
```

### 3. ì‹œê°í™” ì˜¤ë¥˜

#### ì˜¤ë¥˜: "í•œê¸€ í°íŠ¸ê°€ ê¹¨ì§"
```python
# í•´ê²°: í°íŠ¸ ì„¤ì •
import matplotlib.pyplot as plt

# Windows
plt.rcParams['font.family'] = 'Malgun Gothic'

# Mac
plt.rcParams['font.family'] = 'AppleGothic'

# Linux
plt.rcParams['font.family'] = 'NanumGothic'
```

#### ì˜¤ë¥˜: "Figureê°€ í‘œì‹œë˜ì§€ ì•ŠìŒ"
```python
# í•´ê²°: ë°±ì—”ë“œ ë³€ê²½
import matplotlib
matplotlib.use('TkAgg')  # ë˜ëŠ” 'Qt5Agg'
```

### 4. í´ëŸ¬ìŠ¤í„°ë§ ê²½ê³ 

#### ê²½ê³ : "í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ê°€ SKU ê°œìˆ˜ë³´ë‹¤ ë§ìŒ"
```python
# í•´ê²°: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ì¡°ì •
n_skus = dfs.sku_features.shape[0]
n_clusters = min(4, n_skus - 1)
dfs.perform_sku_clustering(n_clusters=n_clusters)
```

#### ê²½ê³ : "ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ"
```python
# í•´ê²°: max_iter ì¦ê°€
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=4, max_iter=1000, random_state=42)
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

```python
# ì²­í¬ ë‹¨ìœ„ë¡œ ë¡œë”©
import pandas as pd

chunks = []
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    chunk = chunk[['date', 'sku_code', 'degr', 'box_qty']]
    chunks.append(chunk)

df = pd.concat(chunks, ignore_index=True)
dfs.load_data(df=df)
```

### 2. ë³‘ë ¬ ì²˜ë¦¬

```python
from multiprocessing import Pool

def process_sku(sku_code):
    # SKUë³„ ì˜ˆì¸¡ ë¡œì§
    pass

# ë³‘ë ¬ ì‹¤í–‰
with Pool(4) as p:
    results = p.map(process_sku, sku_codes)
```

### 3. ìºì‹±

```python
import pickle

# ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
dfs.preprocess_data()
with open('preprocessed_data.pkl', 'wb') as f:
    pickle.dump(dfs, f)

# ì¬ì‚¬ìš©
with open('preprocessed_data.pkl', 'rb') as f:
    dfs = pickle.load(f)
```

---

## ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### 1. ì¼ì¼ ìë™ ì‹¤í–‰

#### Linux/Mac (cron)
```bash
# crontab -e
0 6 * * * cd /path/to/ML && python main.py >> logs/forecast_$(date +\%Y\%m\%d).log 2>&1
```

#### Windows (Task Scheduler)
```powershell
# run_forecast.bat
@echo off
cd C:\path\to\ML
python main.py >> logs\forecast_%date:~0,4%%date:~5,2%%date:~8,2%.log 2>&1
```

### 2. ê²°ê³¼ ìë™ ì´ë©”ì¼ ë°œì†¡

```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders

def send_report_email():
    # ì´ë©”ì¼ ì„¤ì •
    sender = 'forecast@example.com'
    recipients = ['manager@example.com', 'ops@example.com']

    msg = MIMEMultipart()
    msg['From'] = sender
    msg['To'] = ', '.join(recipients)
    msg['Subject'] = f'ìˆ˜ìš”ì˜ˆì¸¡ ë¦¬í¬íŠ¸ - {datetime.now().strftime("%Y-%m-%d")}'

    # ë³¸ë¬¸
    with open('outputs/summary_report.txt', 'r', encoding='utf-8') as f:
        body = f.read()
    msg.attach(MIMEText(body, 'plain', 'utf-8'))

    # ì²¨ë¶€íŒŒì¼
    files = ['forecast_report.csv', 'sku_clustering.png']
    for file in files:
        with open(f'outputs/{file}', 'rb') as f:
            part = MIMEBase('application', 'octet-stream')
            part.set_payload(f.read())
            encoders.encode_base64(part)
            part.add_header('Content-Disposition', f'attachment; filename={file}')
            msg.attach(part)

    # ì „ì†¡
    with smtplib.SMTP('smtp.gmail.com', 587) as server:
        server.starttls()
        server.login(sender, 'password')
        server.send_message(msg)

# main.py ë§ˆì§€ë§‰ì— ì¶”ê°€
if __name__ == "__main__":
    main()
    send_report_email()
```

### 3. API ì„œë²„í™”

```python
from flask import Flask, jsonify, request
import pandas as pd

app = Flask(__name__)
dfs = DemandForecastSystem()

@app.route('/api/forecast', methods=['POST'])
def get_forecast():
    data = request.json
    sku_code = data.get('sku_code')
    days = data.get('days', 7)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    forecast = dfs.generate_forecast_report(forecast_days=days)
    result = forecast[forecast['sku_code'] == sku_code].to_dict('records')

    return jsonify(result)

@app.route('/api/clusters', methods=['GET'])
def get_clusters():
    return jsonify(dfs.sku_features.to_dict('records'))

if __name__ == '__main__':
    # ì´ˆê¸° í•™ìŠµ
    dfs.load_data(data_path='shipment.csv')
    dfs.preprocess_data()
    dfs.create_aggregations()
    dfs.extract_sku_features()
    dfs.perform_sku_clustering()

    # ì„œë²„ ì‹œì‘
    app.run(host='0.0.0.0', port=5000)
```

---

## í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „ í™•ì¸ì‚¬í•­

- [ ] ëª¨ë“  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
- [ ] ë°ì´í„° í˜•ì‹ ê²€ì¦
- [ ] ì¶œë ¥ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
- [ ] ë¡œê·¸ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] ë°±ì—… ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ë¬¸ì„œí™” ì™„ë£Œ
- [ ] ì‚¬ìš©ì êµìœ¡ ì™„ë£Œ

### ìš´ì˜ ì‹œ ëª¨ë‹ˆí„°ë§ í•­ëª©

1. **ë°ì´í„° í’ˆì§ˆ**
   - ì¼ì¼ ë°ì´í„° ìœ ì…ëŸ‰
   - ê²°ì¸¡ì¹˜ ë¹„ìœ¨
   - ì´ìƒì¹˜ íƒì§€

2. **ëª¨ë¸ ì„±ëŠ¥**
   - ì˜ˆì¸¡ ì •í™•ë„ (MAPE)
   - í´ëŸ¬ìŠ¤í„° ì•ˆì •ì„±
   - ì‹¤í–‰ ì‹œê°„

3. **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤**
   - CPU ì‚¬ìš©ë¥ 
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
   - ë””ìŠ¤í¬ ê³µê°„

4. **ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ**
   - ì˜ˆì¸¡ í™œìš©ë¥ 
   - ì¬ê³  íšŒì „ìœ¨ ë³€í™”
   - ë¹„ìš© ì ˆê° íš¨ê³¼

---

## FAQ

### Q1: ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•ŒëŠ”?
**A**: ìµœì†Œ 3ê°œì›” ì´ìƒì˜ ë°ì´í„° ê¶Œì¥. ë¶€ì¡± ì‹œ ë‹¨ìˆœ ëª¨ë¸(ì´ë™í‰ê· ) ì‚¬ìš©

### Q2: ìƒˆë¡œìš´ SKUëŠ” ì–´ë–»ê²Œ ì²˜ë¦¬?
**A**: ì´ˆê¸° 3ê°œì›”ì€ ìœ ì‚¬ SKUì˜ íŒ¨í„´ ì°¸ê³ , ì´í›„ ìë™ í´ëŸ¬ìŠ¤í„°ë§

### Q3: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ëŠ” ì–´ë–»ê²Œ ê²°ì •?
**A**: Elbow method ë˜ëŠ” Silhouette score í™œìš©. ì¼ë°˜ì ìœ¼ë¡œ 3-5ê°œ ê¶Œì¥

### Q4: ì˜ˆì¸¡ì´ ë¶€ì •í™•í•  ë•ŒëŠ”?
**A**:
1. ë” ë§ì€ ë°ì´í„° í™•ë³´
2. íŠ¹ì„± ì¶”ê°€ (í”„ë¡œëª¨ì…˜, ì¬ê³  ë“±)
3. í´ëŸ¬ìŠ¤í„°ë³„ ëª¨ë¸ íŠœë‹

### Q5: ì‹¤ì‹œê°„ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•œê°€?
**A**: ì¼ ë‹¨ìœ„ ë°°ì¹˜ ì²˜ë¦¬ ê¶Œì¥. ì‹¤ì‹œê°„ í•„ìš” ì‹œ API ì„œë²„ êµ¬ì¶•

---

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ê´€ë ¨ ë¬¸ì„œ
- `README.md`: í”„ë¡œì íŠ¸ ê°œìš”
- `CLUSTERING_ANALYSIS.md`: í´ëŸ¬ìŠ¤í„°ë§ ìƒì„¸ ë¶„ì„
- `demand_forecast_system.py`: ì†ŒìŠ¤ ì½”ë“œ (ì£¼ì„ ì°¸ê³ )

### í•™ìŠµ ìë£Œ
- [scikit-learn Clustering Guide](https://scikit-learn.org/stable/modules/clustering.html)
- [Time Series Forecasting Best Practices](https://otexts.com/fpp3/)
- [Inventory Management 101](https://www.ibm.com/topics/inventory-management)

### ì»¤ë®¤ë‹ˆí‹°
- GitHub Issues: ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ê¸°ëŠ¥ ìš”ì²­
- Discussion Forum: ì‚¬ìš© íŒ ê³µìœ 
- Technical Blog: ìµœì‹  ì—…ë°ì´íŠ¸ ë° ì¼€ì´ìŠ¤ ìŠ¤í„°ë””

---

## ë¬¸ì˜

- ê¸°ìˆ  ì§€ì›: tech-support@example.com
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì˜: business@example.com
- ê¸´ê¸‰ ë¬¸ì˜: +82-10-XXXX-XXXX

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024-01-XX
**ë‹´ë‹¹ì**: Logistics AI Team
